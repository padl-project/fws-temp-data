---
title: "Cleaning SeaTemp 2020"
author: "Camila Vargas"
date: "12/3/2021"
output: html_document
---

This scripts cleans csv files provided by Allie Hunter from Fish and Wildlife Service with Temperature data for Palmyra Atoll, data from SeaTempLoggers 2020.

Date range goes from: 

The goal is to determine gaps un data collections and missing information needed to correctly document this data.

## Set up

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## Load packages
library(here)
library(tidyverse)
library(janitor)
library(plotly)

## Sets R not to use scientific notations
options(scipen=999) 

raw_data_path <- here::here("6.raw_data/")
```


## Process data
1. Create a tibble with all the csv that we need to read. Make sure to have a column with site name so we can keep track of this information.

```{r}
all_csv <- tibble(list.files(raw_data_path, pattern = ".csv")) %>% 
  rename(file_name = 1) %>%
  mutate(site_name = str_remove(file_name, "(?<=\\_).+"),
         site_name = str_remove(site_name, "\\_") %>% trimws(.),
         path = paste0(raw_data_path, "/", file_name),
         n = 1:n(),
         type = "temp",
         meta = "meta") %>% 
  unite(obj_name, type, n, sep = "", remove = FALSE) %>% 
  unite(meta_name, meta, n, sep = "", remove = FALSE)
  # separate(col = id2,
  #          into = c("serial_num", "other"),
  #          sep = c("-"," "),
  #          remove = FALSE) %>% 
  # select(-id2, -id3, - other)
```

2. Read each file

```{r}
## general function
read_csv_clean <- function(dataset){
  
  read_csv(dataset, skip = 11) %>% 
    clean_names()
}


for (i in all_csv$n){
  
  assign(all_csv$obj_name[i], read_csv_clean(all_csv$path[i]))
}

```

Seems in this case we do not have repeated data. 

3.Combine all data and add site

Check for duplicates using `distinc()`

```{r}

temp_list <- list(temp1, temp2, temp3, temp4, temp5, temp6, temp7, temp8)

names(temp_list) <- c("temp1", "temp2", "temp3", "temp4", "temp5", "temp6", "temp7", "temp8")

## Check for duplicates - There are 16 rows with same date, time and temperature. Each come from different data sets, temp8 (Sacia) and temp10 (WTerrace). Is this possible??
all_temp <- bind_rows(temp_list) %>% 
  distinct()

test <- bind_rows(temp_list)

dupli <- test %>% 
  group_by_all() %>% 
  filter(n()>1) %>% 
  ungroup()

test2 <- all_temp %>% 
  filter(date == "07/10/2019")

## Temp6 and temp8 seem to have 131 repeated measurments

## End checking -----------

all_temp <- bind_rows(temp_list, .id = "obj_name") %>% 
  distinct()
  

## make sure data of all files in all_tep
all_temp %>% 
  group_by(obj_name) %>% 
  tally()

site_serial <- all_csv %>% 
  separate(col = file_name,
           into = c("id1", "id2", "id3"),
           sep = "_",
           remove = FALSE) %>% 
  mutate(serial_num = str_extract(id2, "\\d{4}[^\\d]*$"),
         serial_num = ifelse(is.na(serial_num), str_extract(id3, "\\d{4}[^\\d]*$"),
                                   serial_num),
         serial_num = str_remove(serial_num, ".csv") %>% trimws(.),
         serial_num = ifelse(is.na(serial_num), "4634", serial_num)) %>%  
  select(obj_name, serial_num, site_name)


final_temp <- all_temp %>% 
  left_join(site_serial, by = "obj_name") %>% 
  select(-obj_name) %>% 
  mutate(year_folder = 2020,
         date = as.Date(date, format = "%m/%d/%Y"))


```



## Checking

Plot
```{r}

plot20 <- final_temp %>% 
  group_by(date, site_name) %>% 
  summarise(mean_temp = mean(temperature)) %>%
  ungroup() %>% 
  ggplot(
  aes(x = date,
      y = mean_temp,
      color = site_name))+
  geom_line()+
  theme_classic()
  
ggplotly(plot20)

```

All looks normal. First days ans last days sometimes is not continious.

Date ranges
```{r}

## Create a table with date range
date_range <- final_temp %>% 
  group_by(site_name) %>% 
  summarise(date_begins = min(date),
         date_ends = max(date))


```


## Save data

```{r}
range(final_temp$date)

write_csv(final_temp, here::here("8.intermediate_files/2018_2020_sea_temp.csv"))

```


## Collect metadata

Read first 11 lines of csv. Lines that contain metadata
```{r}

read_meta <- function(dataset){
  
  read_csv(dataset, n_max = 11, col_names = F)
}


for (i in all_csv$n){
  
  assign(all_csv$meta_name[i], read_meta(all_csv$path[i]))
}

```

Combine all and format
```{r}
meta_list <- list(meta1, meta2, meta3, meta4, meta5, meta6, meta7, meta8)

names(meta_list) <- c("meta1", "meta2", "meta3", "meta4", "meta5", "meta6", "meta7", "meta8")



all_meta <- bind_rows(meta_list, .id = "meta_name") %>% 
  left_join(all_csv, by = "meta_name") %>% 
  select(meta_name, X1, site_name)

metadata <- all_meta %>% 
  mutate(X1 = str_remove(X1, "\\%") %>% trimws(.),
         info = str_extract(X1, "(?<=\\=).+") %>% trimws(.),
         parameter = str_remove(X1, "(?<=\\=).+"),
         parameter = str_remove(parameter, "\\=") %>% trimws(.)) %>% 
  filter(X1 != "Coefficients:") %>% 
  select(site_name, parameter, info) %>% 
  pivot_wider(names_from = parameter,
              values_from = info) %>% 
  clean_names()

```

## Save metadata
```{r}
write_csv(metadata, here::here("8.intermediate_files/2017_2018_metadata.csv"))
```


